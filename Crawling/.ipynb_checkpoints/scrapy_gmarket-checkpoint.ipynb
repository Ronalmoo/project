{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.http import TextResponse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹 페이지에 연결\n",
    "req = requests.get('https://www.naver.com/')\n",
    "\n",
    "# response 객체 생성\n",
    "response = TextResponse(req.url, body=req.text, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='//*[@id=\"PM_ID_ct\"]/div[1]/div[2]/div[2]/div[1]/div/ul/li[1]/a/span[2]' data='<span class=\"ah_k\">로또846회당첨번호</span>'>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.xpath('//*[@id=\"PM_ID_ct\"]/div[1]/div[2]/div[2]/div[1]/div/ul/li[1]/a/span[2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Selector xpath='//*[@id=\"PM_ID_ct\"]/div[1]/div[2]/div[2]/div[1]/div/ul/li[1]/a/span/text()' data='1'>,\n",
       " <Selector xpath='//*[@id=\"PM_ID_ct\"]/div[1]/div[2]/div[2]/div[1]/div/ul/li[1]/a/span/text()' data='로또846회당첨번호'>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text\n",
    "# xpath 가장 뒤에 text() 함수를 작성하면 text 데이터가 있는 object로 변경\n",
    "response.xpath('//*[@id=\"PM_ID_ct\"]/div[1]/div[2]/div[2]/div[1]/div/ul/li[1]/a/span/text()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '로또846회당첨번호']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract\n",
    "# xpath로 select된 element의 데이터를 문자열 리스트로 가져옴\n",
    "response.xpath('//*[@id=\"PM_ID_ct\"]/div[1]/div[2]/div[2]/div[1]/div/ul/li[1]/a/span/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여러개  select해서 데이터 가져오기\n",
    "- 네이버 실시간 키워드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_keywords = response.xpath('//*[@id=\"PM_ID_ct\"]/div[1]/div[2]/div[2]/div[1]/div/ul/li')\n",
    "len(naver_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_rank = naver_keywords.xpath('./a/span[1]/text()').extract()[:10]\n",
    "naver_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['로또846회당첨번호',\n",
       " '비',\n",
       " '금새록',\n",
       " '이범수',\n",
       " '로건',\n",
       " '열혈사제',\n",
       " '정지훈',\n",
       " '드라마 열혈사제',\n",
       " '김희철',\n",
       " '엄복동']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_keywords_list = naver_keywords.xpath('./a/span[2]/text()').extract()[:10]\n",
    "naver_keywords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- 다음 실시간 키워드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 웹 페이지에 연결\n",
    "req = requests.get('https://www.daum.net/')\n",
    "\n",
    "# response 객체 생성\n",
    "response = TextResponse(req.url, body=req.text, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 https://www.daum.net/>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1위', '2위', '3위', '4위', '5위', '6위', '7위', '8위', '9위', '10위']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 순위\n",
    "response.xpath('//*[@id=\"mArticle\"]/div[2]/div[1]/div[2]/div[1]/ol/li/div/div[1]/span[1]/span/text()').extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['플립',\n",
       " '채리나',\n",
       " '비',\n",
       " '846회 로또 당첨 번호',\n",
       " '세븐틴',\n",
       " '박성중 의원',\n",
       " '금새록',\n",
       " '쑤저우',\n",
       " '그것이 알고 싶다',\n",
       " '이범수']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 키워드\n",
    "response.xpath('//*[@id=\"mArticle\"]/div[2]/div[1]/div[3]/div[1]/ol/li/div/div/span[2]/a/text()').extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapy Project\n",
    "- g마켓 베스트셀러 상품, 상품평\n",
    "- http://corners.gmarket.co.kr/Bestsellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Scrapy project 'crawler', using template directory '/Users/seungmoo/.pyenv/versions/3.6.0/envs/tensorflow/lib/python3.6/site-packages/scrapy/templates/project', created in:\r\n",
      "    /Users/seungmoo/SM/Workspace/project/crawler\r\n",
      "\r\n",
      "You can start your first spider with:\r\n",
      "    cd crawler\r\n",
      "    scrapy genspider example example.com\r\n"
     ]
    }
   ],
   "source": [
    "!scrapy startproject crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mcrawler\u001b[00m\r\n",
      "├── \u001b[01;34mcrawler\u001b[00m\r\n",
      "│   ├── __init__.py\r\n",
      "│   ├── \u001b[01;34m__pycache__\u001b[00m\r\n",
      "│   ├── items.py\r\n",
      "│   ├── middlewares.py\r\n",
      "│   ├── pipelines.py\r\n",
      "│   ├── settings.py\r\n",
      "│   └── \u001b[01;34mspiders\u001b[00m\r\n",
      "│       ├── __init__.py\r\n",
      "│       └── \u001b[01;34m__pycache__\u001b[00m\r\n",
      "└── scrapy.cfg\r\n",
      "\r\n",
      "4 directories, 7 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scrapy 기본구조\n",
    "- Spider\n",
    "    - 어떤 웹사이트들을 어떻게 크롤링할 것인지 명시하고, 각각의 웹페이지의 어떤 부분을 스크래핑할 것인지 명시하는 클래스\n",
    "\n",
    "- items.py\n",
    "    - 웹페이지에서 원하는 부분을 스크랩하여 저장할 때 사용하는 사용자 정의 자료구조 클래스\n",
    "\n",
    "- pipelines.py\n",
    "    - 스크래핑 결과물을 Item 형태로 구성하였을 때, 이를 자유롭게 가공하거나 다양한 파일 형태로 저장할 수 있도록 하는 클래스 (getter와 setter의 개념)\n",
    "\n",
    "- settings.py\n",
    "\n",
    "    - Spider나 Item Pipeline 등이 어떻게 동작하도록 할 지에 대한 세부적인 설정 사항을 기재하는 파일 크롤링의 빈도등을 설정\n",
    "    - cf. robots.txt (settings.py - ROBOTSTXT_OBEY = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 베스트 셀러 상품 200개의 엘리먼트를 selecting\n",
    "req = requests.get('http://corners.gmarket.co.kr/Bestsellers')\n",
    "response = TextResponse(req.url, body=req.text, encoding='utf-8')\n",
    "bestsellers = response.xpath('//*[@id=\"gBestWrap\"]/div/div[3]/div[2]/ul/li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bestsellers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 'NEW 리뉴얼 그로미미 PPSU 빨대컵/빨대젖병 + 교체용빨대2개입')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 타이틀 데이터를 가져옴\n",
    "titles = bestsellers.xpath('./a/text()').extract()\n",
    "len(titles), titles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 'http://item.gmarket.co.kr/Item?goodscode=1531372264')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 상품 200개의 엘리먼트에서 링크 데이터를 가져옴\n",
    "# links가 path로 되어있을때, 전체 URL을 얻으려면 response.urljoin(path)로 실행\n",
    "links = bestsellers.xpath('./a/@href').extract()\n",
    "len(links), links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://item.gmarket.co.kr/Item?goodscode=1531372264']\n",
      "['http://item.gmarket.co.kr/Item?goodscode=1551166971']\n",
      "['http://item.gmarket.co.kr/Item?goodscode=746916620']\n",
      "['http://item.gmarket.co.kr/Item?goodscode=1513973750']\n",
      "['http://item.gmarket.co.kr/Item?goodscode=1544688889']\n"
     ]
    }
   ],
   "source": [
    "# 링크 데이터를 가져옴\n",
    "bestsellers = response.xpath('//*[@id=\"gBestWrap\"]/div/div[3]/div[2]/ul/li')[:5]\n",
    "for bestseller in bestsellers:\n",
    "    link = bestseller.xpath('./a/@href').extract()\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mcrawler\u001b[00m\r\n",
      "├── \u001b[01;34mcrawler\u001b[00m\r\n",
      "│   ├── __init__.py\r\n",
      "│   ├── \u001b[01;34m__pycache__\u001b[00m\r\n",
      "│   ├── items.py\r\n",
      "│   ├── middlewares.py\r\n",
      "│   ├── pipelines.py\r\n",
      "│   ├── settings.py\r\n",
      "│   └── \u001b[01;34mspiders\u001b[00m\r\n",
      "│       ├── __init__.py\r\n",
      "│       └── \u001b[01;34m__pycache__\u001b[00m\r\n",
      "└── scrapy.cfg\r\n",
      "\r\n",
      "4 directories, 7 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 상세 페이지 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상세 페이지 접속\n",
    "req = requests.get(link[0])\n",
    "response = TextResponse(req.url, body=req.text, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://item.gmarket.co.kr/Item?goodscode=1544688889']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 http://item.gmarket.co.kr/Item?goodscode=1544688889>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Selector xpath='//*[@id=\"itemcase_basic\"]/h1/text()' data='김하진 자연육수 다시팩 100팩(멸치/해물/얼큰) '>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 제목\n",
    "title = response.xpath('//*[@id=\"itemcase_basic\"]/h1/text()')[0]\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'36910'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 판매가\n",
    "s_price = response.xpath('//*[@id=\"itemcase_basic\"]/p/span/strong/text()')[0].extract().replace(\",\", '')\n",
    "s_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<200 http://item.gmarket.co.kr/Item?goodscode=1555059085>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'39900'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원가\n",
    "o_price = response.xpath('//*[@id=\"itemcase_basic\"]/p/span/span/text()')[0].extract().replace(',', '')\n",
    "o_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7.5'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 할인율\n",
    "discount_rate = str(round((1 - int(s_price) / int(o_price)) * 100, 1))\n",
    "discount_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925062656641604"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36910 / 39900"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting crawler/crawler/items.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile crawler/crawler/items.py\n",
    "import scrapy\n",
    "\n",
    "class CrawlerItem(scrapy.Item):\n",
    "    title = scrapy.Field()\n",
    "    s_price = scrapy.Field()\n",
    "    o_price = scrapy.Field()\n",
    "    discount_rate = scrapy.Field()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import scrapy\r\n",
      "\r\n",
      "class CrawlerItem(scrapy.Item):\r\n",
      "    title = scrapy.Field()\r\n",
      "    s_price = scrapy.Field()\r\n",
      "    o_price = scrapy.Field()\r\n",
      "    discount_rate = scrapy.Field()\r\n"
     ]
    }
   ],
   "source": [
    "!cat crawler/crawler/items.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing crawler/crawler/spiders/spider.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile crawler/crawler/spiders/spider.py\n",
    "import scrapy\n",
    "\n",
    "from crawler.items import CrawlerItem\n",
    "\n",
    "# start_urls -> parse -> parse_page_contents 순으로 호출\n",
    "class Spider(scrapy.Spider):\n",
    "    # 스파이더의 이름\n",
    "    name = \"GmarketBestsellers\"\n",
    "    allow_domain = [\"gmarket.co.kr\"]\n",
    "    # 크롤링의 시작 URL\n",
    "    start_urls = [\"http://corners.gmarket.co.kr/Bestsellers\"]\n",
    "\n",
    "    # link 리스트를 가져옴\n",
    "    def parse(self, response):\n",
    "        bestsellers = response.xpath('//*[@id=\"gBestWrap\"]/div/div[3]/div[2]/ul/li')[:10]\n",
    "        for bestseller in bestsellers:\n",
    "            link = bestseller.xpath('./a/@href').extract()[0]\n",
    "            # 각 링크마다 parse_page_contents 함수를 호출\n",
    "            yield scrapy.Request(link, callback=self.parse_page_contents)\n",
    "\n",
    "    # 각페이지의 link로 접속하여 데이터를 가져옴\n",
    "    def parse_page_contents(self, response):\n",
    "        item = CrawlerItem()\n",
    "        item[\"title\"] = response.xpath('//*[@id=\"itemcase_basic\"]/h1/text()')[0].extract().strip()\n",
    "        item[\"s_price\"] = response.xpath('//*[@id=\"itemcase_basic\"]/p/span/strong/text()')[0].extract().replace(\",\",\"\")\n",
    "        # 원가가 없는 경우 판매가를 넣음\n",
    "        try:\n",
    "            item[\"o_price\"] = response.xpath('//*[@id=\"itemcase_basic\"]/p/span/span/text()')[0].extract().replace(\",\",\"\")\n",
    "        except:\n",
    "            item[\"o_price\"] = item[\"s_price\"]\n",
    "        item[\"discount_rate\"] = str(round((1 - int(item[\"s_price\"]) / int(item[\"o_price\"])) * 100, 2)) + \"%\"\n",
    "        yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import scrapy\r\n",
      "\r\n",
      "from crawler.items import CrawlerItem\r\n",
      "\r\n",
      "# start_urls -> parse -> parse_page_contents 순으로 호출\r\n",
      "class Spider(scrapy.Spider):\r\n",
      "    # 스파이더의 이름\r\n",
      "    name = \"GmarketBestsellers\"\r\n",
      "    allow_domain = [\"gmarket.co.kr\"]\r\n",
      "    # 크롤링의 시작 URL\r\n",
      "    start_urls = [\"http://corners.gmarket.co.kr/Bestsellers\"]\r\n",
      "\r\n",
      "    # link 리스트를 가져옴\r\n",
      "    def parse(self, response):\r\n",
      "        bestsellers = response.xpath('//*[@id=\"gBestWrap\"]/div/div[3]/div[2]/ul/li')[:10]\r\n",
      "        for bestseller in bestsellers:\r\n",
      "            link = bestseller.xpath('./a/@href').extract()[0]\r\n",
      "            # 각 링크마다 parse_page_contents 함수를 호출\r\n",
      "            yield scrapy.Request(link, callback=self.parse_page_contents)\r\n",
      "\r\n",
      "    # 각페이지의 link로 접속하여 데이터를 가져옴\r\n",
      "    def parse_page_contents(self, response):\r\n",
      "        item = CrawlerItem()\r\n",
      "        item[\"title\"] = response.xpath('//*[@id=\"itemcase_basic\"]/h1/text()')[0].extract().strip()\r\n",
      "        item[\"s_price\"] = response.xpath('//*[@id=\"itemcase_basic\"]/p/span/strong/text()')[0].extract().replace(\",\",\"\")\r\n",
      "        # 원가가 없는 경우 판매가를 넣음\r\n",
      "        try:\r\n",
      "            item[\"o_price\"] = response.xpath('//*[@id=\"itemcase_basic\"]/p/span/span/text()')[0].extract().replace(\",\",\"\")\r\n",
      "        except:\r\n",
      "            item[\"o_price\"] = item[\"s_price\"]\r\n",
      "        item[\"discount_rate\"] = str(round((1 - int(item[\"s_price\"]) / int(item[\"o_price\"])) * 100, 2)) + \"%\"\r\n",
      "        yield item\r\n"
     ]
    }
   ],
   "source": [
    "!cat crawler/crawler/spiders/spider.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mcrawler\u001b[m\u001b[m    scrapy.cfg\r\n"
     ]
    }
   ],
   "source": [
    "!ls crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mcrawler\u001b[00m\r\n",
      "├── \u001b[01;34mcrawler\u001b[00m\r\n",
      "│   ├── __init__.py\r\n",
      "│   ├── \u001b[01;34m__pycache__\u001b[00m\r\n",
      "│   ├── items.py\r\n",
      "│   ├── middlewares.py\r\n",
      "│   ├── pipelines.py\r\n",
      "│   ├── settings.py\r\n",
      "│   └── \u001b[01;34mspiders\u001b[00m\r\n",
      "│       ├── __init__.py\r\n",
      "│       └── \u001b[01;34m__pycache__\u001b[00m\r\n",
      "└── scrapy.cfg\r\n",
      "\r\n",
      "4 directories, 7 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.sh\n",
    "cd crawler\n",
    "scrapy crawl GmarketBestsellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-17 19:53:18 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: crawler)\n",
      "2019-02-17 19:53:18 [scrapy.utils.log] INFO: Versions: lxml 4.3.1.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.6.0 (default, Jan 15 2019, 09:54:55) - [GCC 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1a  20 Nov 2018), cryptography 2.5, Platform Darwin-17.7.0-x86_64-i386-64bit\n",
      "2019-02-17 19:53:18 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'crawler', 'NEWSPIDER_MODULE': 'crawler.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['crawler.spiders']}\n",
      "2019-02-17 19:53:18 [scrapy.extensions.telnet] INFO: Telnet Password: ce8628ade126bbbc\n",
      "2019-02-17 19:53:18 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2019-02-17 19:53:19 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2019-02-17 19:53:19 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2019-02-17 19:53:19 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2019-02-17 19:53:19 [scrapy.core.engine] INFO: Spider opened\n",
      "2019-02-17 19:53:19 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2019-02-17 19:53:19 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2019-02-17 19:53:19 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.gmarket.co.kr/Error_log/error_myg.asp?aspxerrorpath=/robots.txt> from <GET http://corners.gmarket.co.kr/robots.txt>\n",
      "2019-02-17 19:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.gmarket.co.kr/Error_log/error_myg.asp?aspxerrorpath=/robots.txt> (referer: None)\n",
      "2019-02-17 19:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://corners.gmarket.co.kr/Bestsellers> (referer: None)\n",
      "2019-02-17 19:53:19 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/robots.txt> (referer: None)\n",
      "2019-02-17 19:53:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=864233619> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:53:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1559987707> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:53:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1552432834> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:53:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1549335525> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:53:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=864233619>\n",
      "{'discount_rate': '4.97%',\n",
      " 'o_price': '31360',\n",
      " 's_price': '29800',\n",
      " 'title': '[비달사순] 비달사순 40mm 아이롱/매직기/봉고데기 VSCD746K'}\n",
      "2019-02-17 19:53:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1559987707>\n",
      "{'discount_rate': '50.0%',\n",
      " 'o_price': '23800',\n",
      " 's_price': '11900',\n",
      " 'title': '[GFresh] 보성 흑토마토 2kg(대~3번과 혼합)'}\n",
      "2019-02-17 19:53:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1552432834>\n",
      "{'discount_rate': '0.0%',\n",
      " 'o_price': '20000',\n",
      " 's_price': '20000',\n",
      " 'title': '[이지오] 모다아울렛 S/S 이월 정장세트 5만원 外'}\n",
      "2019-02-17 19:53:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1549335525>\n",
      "{'discount_rate': '28.28%',\n",
      " 'o_price': '39000',\n",
      " 's_price': '27970',\n",
      " 'title': '[아디다스] (신세계경기점) MENS RUNNING  플루이드/솔릭스 (CG3820 BB7614 B43697 '\n",
      "          'B43698)'}\n",
      "2019-02-17 19:53:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1531372264> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:53:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1544688889> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:53:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1513973750> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:53:20 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1556101689> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:53:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1531372264>\n",
      "{'discount_rate': '0.0%',\n",
      " 'o_price': '23850',\n",
      " 's_price': '23850',\n",
      " 'title': 'NEW 리뉴얼 그로미미 PPSU 빨대컵/빨대젖병 + 교체용빨대2개입'}\n",
      "2019-02-17 19:53:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1544688889>\n",
      "{'discount_rate': '7.49%',\n",
      " 'o_price': '39900',\n",
      " 's_price': '36910',\n",
      " 'title': '김하진 자연육수 다시팩 100팩(멸치/해물/얼큰)'}\n",
      "2019-02-17 19:53:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1513973750>\n",
      "{'discount_rate': '59.9%',\n",
      " 'o_price': '19700',\n",
      " 's_price': '7900',\n",
      " 'title': '메이킹유 여성 데님/빅사이즈/청바지/루즈핏/셔츠'}\n",
      "2019-02-17 19:53:20 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1556101689>\n",
      "{'discount_rate': '29.24%',\n",
      " 'o_price': '33000',\n",
      " 's_price': '23350',\n",
      " 'title': '[디아도라] (신세계강남점)디아도라 컨템포러리 스니커즈 런닝화 14종 택1 DS17XXXX'}\n",
      "2019-02-17 19:53:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=746916620> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:53:21 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1551166971> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:53:21 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=746916620>\n",
      "{'discount_rate': '70.0%',\n",
      " 'o_price': '23000',\n",
      " 's_price': '6900',\n",
      " 'title': '[릴리푸리] 릴리푸리/빌리진/봄신상/무료배송/원피스/티셔츠/세트'}\n",
      "2019-02-17 19:53:21 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1551166971>\n",
      "{'discount_rate': '15.69%',\n",
      " 'o_price': '25500',\n",
      " 's_price': '21500',\n",
      " 'title': '[케이스위스] 깔끔하고 편안한 남여 캐주얼 코트화 8종 4116SP104/ 케이스위스'}\n",
      "2019-02-17 19:53:21 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2019-02-17 19:53:21 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 6864,\n",
      " 'downloader/request_count': 14,\n",
      " 'downloader/request_method_count/GET': 14,\n",
      " 'downloader/response_bytes': 368697,\n",
      " 'downloader/response_count': 14,\n",
      " 'downloader/response_status_count/200': 13,\n",
      " 'downloader/response_status_count/302': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 2, 17, 10, 53, 21, 185690),\n",
      " 'item_scraped_count': 10,\n",
      " 'log_count/DEBUG': 24,\n",
      " 'log_count/INFO': 9,\n",
      " 'memusage/max': 51249152,\n",
      " 'memusage/startup': 51249152,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 13,\n",
      " 'robotstxt/request_count': 2,\n",
      " 'robotstxt/response_count': 2,\n",
      " 'robotstxt/response_status_count/200': 2,\n",
      " 'scheduler/dequeued': 11,\n",
      " 'scheduler/dequeued/memory': 11,\n",
      " 'scheduler/enqueued': 11,\n",
      " 'scheduler/enqueued/memory': 11,\n",
      " 'start_time': datetime.datetime(2019, 2, 17, 10, 53, 19, 66526)}\n",
      "2019-02-17 19:53:21 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!source run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.sh\n",
    "cd crawler\n",
    "scrapy crawl GmarketBestsellers -o GmarketBestsellers.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-17 19:54:49 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: crawler)\n",
      "2019-02-17 19:54:49 [scrapy.utils.log] INFO: Versions: lxml 4.3.1.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.6.0 (default, Jan 15 2019, 09:54:55) - [GCC 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1a  20 Nov 2018), cryptography 2.5, Platform Darwin-17.7.0-x86_64-i386-64bit\n",
      "2019-02-17 19:54:49 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'crawler', 'FEED_FORMAT': 'csv', 'FEED_URI': 'GmarketBestsellers.csv', 'NEWSPIDER_MODULE': 'crawler.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['crawler.spiders']}\n",
      "2019-02-17 19:54:49 [scrapy.extensions.telnet] INFO: Telnet Password: 36f73e8eee74cd52\n",
      "2019-02-17 19:54:49 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.feedexport.FeedExporter',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2019-02-17 19:54:49 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2019-02-17 19:54:49 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2019-02-17 19:54:49 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2019-02-17 19:54:49 [scrapy.core.engine] INFO: Spider opened\n",
      "2019-02-17 19:54:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2019-02-17 19:54:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2019-02-17 19:54:49 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.gmarket.co.kr/Error_log/error_myg.asp?aspxerrorpath=/robots.txt> from <GET http://corners.gmarket.co.kr/robots.txt>\n",
      "2019-02-17 19:54:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.gmarket.co.kr/Error_log/error_myg.asp?aspxerrorpath=/robots.txt> (referer: None)\n",
      "2019-02-17 19:54:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://corners.gmarket.co.kr/Bestsellers> (referer: None)\n",
      "2019-02-17 19:54:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/robots.txt> (referer: None)\n",
      "2019-02-17 19:54:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1544688889> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:54:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1531372264> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:54:50 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1559987707> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:54:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1544688889>\n",
      "{'discount_rate': '7.49%',\n",
      " 'o_price': '39900',\n",
      " 's_price': '36910',\n",
      " 'title': '김하진 자연육수 다시팩 100팩(멸치/해물/얼큰)'}\n",
      "2019-02-17 19:54:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1531372264>\n",
      "{'discount_rate': '0.0%',\n",
      " 'o_price': '23850',\n",
      " 's_price': '23850',\n",
      " 'title': 'NEW 리뉴얼 그로미미 PPSU 빨대컵/빨대젖병 + 교체용빨대2개입'}\n",
      "2019-02-17 19:54:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1559987707>\n",
      "{'discount_rate': '50.0%',\n",
      " 'o_price': '23800',\n",
      " 's_price': '11900',\n",
      " 'title': '[GFresh] 보성 흑토마토 2kg(대~3번과 혼합)'}\n",
      "2019-02-17 19:54:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=864233619> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:54:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1549335525> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:54:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1556101689> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:54:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1513973750> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:54:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=864233619>\n",
      "{'discount_rate': '4.97%',\n",
      " 'o_price': '31360',\n",
      " 's_price': '29800',\n",
      " 'title': '[비달사순] 비달사순 40mm 아이롱/매직기/봉고데기 VSCD746K'}\n",
      "2019-02-17 19:54:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1549335525>\n",
      "{'discount_rate': '28.28%',\n",
      " 'o_price': '39000',\n",
      " 's_price': '27970',\n",
      " 'title': '[아디다스] (신세계경기점) MENS RUNNING  플루이드/솔릭스 (CG3820 BB7614 B43697 '\n",
      "          'B43698)'}\n",
      "2019-02-17 19:54:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1556101689>\n",
      "{'discount_rate': '29.24%',\n",
      " 'o_price': '33000',\n",
      " 's_price': '23350',\n",
      " 'title': '[디아도라] (신세계강남점)디아도라 컨템포러리 스니커즈 런닝화 14종 택1 DS17XXXX'}\n",
      "2019-02-17 19:54:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1513973750>\n",
      "{'discount_rate': '59.9%',\n",
      " 'o_price': '19700',\n",
      " 's_price': '7900',\n",
      " 'title': '메이킹유 여성 데님/빅사이즈/청바지/루즈핏/셔츠'}\n",
      "2019-02-17 19:54:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1552432834> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:54:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1552432834>\n",
      "{'discount_rate': '0.0%',\n",
      " 'o_price': '20000',\n",
      " 's_price': '20000',\n",
      " 'title': '[이지오] 모다아울렛 S/S 이월 정장세트 5만원 外'}\n",
      "2019-02-17 19:54:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1551166971> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:54:51 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=746916620> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 19:54:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1551166971>\n",
      "{'discount_rate': '15.69%',\n",
      " 'o_price': '25500',\n",
      " 's_price': '21500',\n",
      " 'title': '[케이스위스] 깔끔하고 편안한 남여 캐주얼 코트화 8종 4116SP104/ 케이스위스'}\n",
      "2019-02-17 19:54:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=746916620>\n",
      "{'discount_rate': '70.0%',\n",
      " 'o_price': '23000',\n",
      " 's_price': '6900',\n",
      " 'title': '[릴리푸리] 릴리푸리/빌리진/봄신상/무료배송/원피스/티셔츠/세트'}\n",
      "2019-02-17 19:54:51 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2019-02-17 19:54:51 [scrapy.extensions.feedexport] INFO: Stored csv feed (10 items) in: GmarketBestsellers.csv\n",
      "2019-02-17 19:54:51 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 6884,\n",
      " 'downloader/request_count': 14,\n",
      " 'downloader/request_method_count/GET': 14,\n",
      " 'downloader/response_bytes': 368739,\n",
      " 'downloader/response_count': 14,\n",
      " 'downloader/response_status_count/200': 13,\n",
      " 'downloader/response_status_count/302': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 2, 17, 10, 54, 51, 723747),\n",
      " 'item_scraped_count': 10,\n",
      " 'log_count/DEBUG': 24,\n",
      " 'log_count/INFO': 10,\n",
      " 'memusage/max': 52011008,\n",
      " 'memusage/startup': 52011008,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 13,\n",
      " 'robotstxt/request_count': 2,\n",
      " 'robotstxt/response_count': 2,\n",
      " 'robotstxt/response_status_count/200': 2,\n",
      " 'scheduler/dequeued': 11,\n",
      " 'scheduler/dequeued/memory': 11,\n",
      " 'scheduler/enqueued': 11,\n",
      " 'scheduler/enqueued/memory': 11,\n",
      " 'start_time': datetime.datetime(2019, 2, 17, 10, 54, 49, 657346)}\n",
      "2019-02-17 19:54:51 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!source run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GmarketBestsellers.csv \u001b[1m\u001b[36mcrawler\u001b[m\u001b[m                scrapy.cfg\r\n"
     ]
    }
   ],
   "source": [
    "!ls crawler/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discount_rate</th>\n",
       "      <th>o_price</th>\n",
       "      <th>s_price</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.49%</td>\n",
       "      <td>39900</td>\n",
       "      <td>36910</td>\n",
       "      <td>김하진 자연육수 다시팩 100팩(멸치/해물/얼큰)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>23850</td>\n",
       "      <td>23850</td>\n",
       "      <td>NEW 리뉴얼 그로미미 PPSU 빨대컵/빨대젖병 + 교체용빨대2개입</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.0%</td>\n",
       "      <td>23800</td>\n",
       "      <td>11900</td>\n",
       "      <td>[GFresh] 보성 흑토마토 2kg(대~3번과 혼합)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.97%</td>\n",
       "      <td>31360</td>\n",
       "      <td>29800</td>\n",
       "      <td>[비달사순] 비달사순 40mm 아이롱/매직기/봉고데기 VSCD746K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.28%</td>\n",
       "      <td>39000</td>\n",
       "      <td>27970</td>\n",
       "      <td>[아디다스] (신세계경기점) MENS RUNNING  플루이드/솔릭스 (CG3820...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>29.24%</td>\n",
       "      <td>33000</td>\n",
       "      <td>23350</td>\n",
       "      <td>[디아도라] (신세계강남점)디아도라 컨템포러리 스니커즈 런닝화 14종 택1 DS17...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>59.9%</td>\n",
       "      <td>19700</td>\n",
       "      <td>7900</td>\n",
       "      <td>메이킹유 여성 데님/빅사이즈/청바지/루즈핏/셔츠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0%</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>[이지오] 모다아울렛 S/S 이월 정장세트 5만원 外</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15.69%</td>\n",
       "      <td>25500</td>\n",
       "      <td>21500</td>\n",
       "      <td>[케이스위스] 깔끔하고 편안한 남여 캐주얼 코트화 8종 4116SP104/ 케이스위스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70.0%</td>\n",
       "      <td>23000</td>\n",
       "      <td>6900</td>\n",
       "      <td>[릴리푸리] 릴리푸리/빌리진/봄신상/무료배송/원피스/티셔츠/세트</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  discount_rate  o_price  s_price  \\\n",
       "0         7.49%    39900    36910   \n",
       "1          0.0%    23850    23850   \n",
       "2         50.0%    23800    11900   \n",
       "3         4.97%    31360    29800   \n",
       "4        28.28%    39000    27970   \n",
       "5        29.24%    33000    23350   \n",
       "6         59.9%    19700     7900   \n",
       "7          0.0%    20000    20000   \n",
       "8        15.69%    25500    21500   \n",
       "9         70.0%    23000     6900   \n",
       "\n",
       "                                               title  \n",
       "0                        김하진 자연육수 다시팩 100팩(멸치/해물/얼큰)  \n",
       "1              NEW 리뉴얼 그로미미 PPSU 빨대컵/빨대젖병 + 교체용빨대2개입  \n",
       "2                     [GFresh] 보성 흑토마토 2kg(대~3번과 혼합)  \n",
       "3             [비달사순] 비달사순 40mm 아이롱/매직기/봉고데기 VSCD746K  \n",
       "4  [아디다스] (신세계경기점) MENS RUNNING  플루이드/솔릭스 (CG3820...  \n",
       "5  [디아도라] (신세계강남점)디아도라 컨템포러리 스니커즈 런닝화 14종 택1 DS17...  \n",
       "6                         메이킹유 여성 데님/빅사이즈/청바지/루즈핏/셔츠  \n",
       "7                      [이지오] 모다아울렛 S/S 이월 정장세트 5만원 外  \n",
       "8    [케이스위스] 깔끔하고 편안한 남여 캐주얼 코트화 8종 4116SP104/ 케이스위스  \n",
       "9                [릴리푸리] 릴리푸리/빌리진/봄신상/무료배송/원피스/티셔츠/세트  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('crawler/GmarketBestsellers.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "- 결과를 깔끔하게 정리해서 저장\n",
    "- spider의 items 데이터가 pipelines에 정의된대로 저장\n",
    "- pipelines.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting crawler/crawler/pipelines.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile crawler/crawler/pipelines.py\n",
    "import csv\n",
    "\n",
    "class CrawlerPipeline(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.csvwriter = csv.writer(open(\"GmarketBestsellers.csv\", \"w\"))\n",
    "        self.csvwriter.writerow([\"title\",\"o_price\",\"s_price\",\"discount_rate\"])\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        row = []\n",
    "        row.append(item[\"title\"])\n",
    "        row.append(item[\"o_price\"])\n",
    "        row.append(item[\"s_price\"])\n",
    "        row.append(item[\"discount_rate\"])\n",
    "        self.csvwriter.writerow(row)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import csv\r\n",
      "\r\n",
      "class CrawlerPipeline(object):\r\n",
      "\r\n",
      "    def __init__(self):\r\n",
      "        self.csvwriter = csv.writer(open(\"GmarketBestsellers.csv\", \"w\"))\r\n",
      "        self.csvwriter.writerow([\"title\",\"o_price\",\"s_price\",\"discount_rate\"])\r\n",
      "\r\n",
      "    def process_item(self, item, spider):\r\n",
      "        row = []\r\n",
      "        row.append(item[\"title\"])\r\n",
      "        row.append(item[\"o_price\"])\r\n",
      "        row.append(item[\"s_price\"])\r\n",
      "        row.append(item[\"discount_rate\"])\r\n",
      "        self.csvwriter.writerow(row)\r\n",
      "        return item\r\n"
     ]
    }
   ],
   "source": [
    "!cat crawler/crawler/pipelines.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"ITEM_PIPELINES = {\" >> crawler/crawler/settings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"   'crawler.pipelines.CrawlerPipeline': 300,\" >> crawler/crawler/settings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"}\" >> crawler/crawler/settings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITEM_PIPELINES = {\r\n",
      "   'crawler.pipelines.CrawlerPipeline': 300,\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 3 crawler/crawler/settings.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile run.sh\n",
    "cd crawler\n",
    "scrapy crawl GmarketBestsellers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-17 20:00:00 [scrapy.utils.log] INFO: Scrapy 1.6.0 started (bot: crawler)\n",
      "2019-02-17 20:00:00 [scrapy.utils.log] INFO: Versions: lxml 4.3.1.0, libxml2 2.9.9, cssselect 1.0.3, parsel 1.5.1, w3lib 1.20.0, Twisted 18.9.0, Python 3.6.0 (default, Jan 15 2019, 09:54:55) - [GCC 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.5)], pyOpenSSL 19.0.0 (OpenSSL 1.1.1a  20 Nov 2018), cryptography 2.5, Platform Darwin-17.7.0-x86_64-i386-64bit\n",
      "2019-02-17 20:00:00 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'crawler', 'NEWSPIDER_MODULE': 'crawler.spiders', 'ROBOTSTXT_OBEY': True, 'SPIDER_MODULES': ['crawler.spiders']}\n",
      "2019-02-17 20:00:00 [scrapy.extensions.telnet] INFO: Telnet Password: 3bc4371d9968b10a\n",
      "2019-02-17 20:00:00 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2019-02-17 20:00:00 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2019-02-17 20:00:00 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2019-02-17 20:00:00 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "['crawler.pipelines.CrawlerPipeline']\n",
      "2019-02-17 20:00:00 [scrapy.core.engine] INFO: Spider opened\n",
      "2019-02-17 20:00:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2019-02-17 20:00:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2019-02-17 20:00:00 [scrapy.downloadermiddlewares.redirect] DEBUG: Redirecting (302) to <GET http://www.gmarket.co.kr/Error_log/error_myg.asp?aspxerrorpath=/robots.txt> from <GET http://corners.gmarket.co.kr/robots.txt>\n",
      "2019-02-17 20:00:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.gmarket.co.kr/Error_log/error_myg.asp?aspxerrorpath=/robots.txt> (referer: None)\n",
      "2019-02-17 20:00:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://corners.gmarket.co.kr/Bestsellers> (referer: None)\n",
      "2019-02-17 20:00:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/robots.txt> (referer: None)\n",
      "2019-02-17 20:00:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1549335525> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 20:00:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1544688889> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 20:00:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1531372264> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 20:00:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1556101689> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 20:00:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1549335525>\n",
      "{'discount_rate': '28.28%',\n",
      " 'o_price': '39000',\n",
      " 's_price': '27970',\n",
      " 'title': '[아디다스] (신세계경기점) MENS RUNNING  플루이드/솔릭스 (CG3820 BB7614 B43697 '\n",
      "          'B43698)'}\n",
      "2019-02-17 20:00:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1544688889>\n",
      "{'discount_rate': '7.49%',\n",
      " 'o_price': '39900',\n",
      " 's_price': '36910',\n",
      " 'title': '김하진 자연육수 다시팩 100팩(멸치/해물/얼큰)'}\n",
      "2019-02-17 20:00:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1531372264>\n",
      "{'discount_rate': '0.0%',\n",
      " 'o_price': '23850',\n",
      " 's_price': '23850',\n",
      " 'title': 'NEW 리뉴얼 그로미미 PPSU 빨대컵/빨대젖병 + 교체용빨대2개입'}\n",
      "2019-02-17 20:00:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1556101689>\n",
      "{'discount_rate': '29.24%',\n",
      " 'o_price': '33000',\n",
      " 's_price': '23350',\n",
      " 'title': '[디아도라] (신세계강남점)디아도라 컨템포러리 스니커즈 런닝화 14종 택1 DS17XXXX'}\n",
      "2019-02-17 20:00:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1559987707> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 20:00:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=864233619> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 20:00:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1513973750> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 20:00:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1559987707>\n",
      "{'discount_rate': '50.0%',\n",
      " 'o_price': '23800',\n",
      " 's_price': '11900',\n",
      " 'title': '[GFresh] 보성 흑토마토 2kg(대~3번과 혼합)'}\n",
      "2019-02-17 20:00:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=864233619>\n",
      "{'discount_rate': '4.97%',\n",
      " 'o_price': '31360',\n",
      " 's_price': '29800',\n",
      " 'title': '[비달사순] 비달사순 40mm 아이롱/매직기/봉고데기 VSCD746K'}\n",
      "2019-02-17 20:00:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1513973750>\n",
      "{'discount_rate': '59.9%',\n",
      " 'o_price': '19700',\n",
      " 's_price': '7900',\n",
      " 'title': '메이킹유 여성 데님/빅사이즈/청바지/루즈핏/셔츠'}\n",
      "2019-02-17 20:00:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1552432834> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 20:00:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1552432834>\n",
      "{'discount_rate': '0.0%',\n",
      " 'o_price': '20000',\n",
      " 's_price': '20000',\n",
      " 'title': '[이지오] 모다아울렛 S/S 이월 정장세트 5만원 外'}\n",
      "2019-02-17 20:00:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=1551166971> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 20:00:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://item.gmarket.co.kr/Item?goodscode=746916620> (referer: http://corners.gmarket.co.kr/Bestsellers)\n",
      "2019-02-17 20:00:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=1551166971>\n",
      "{'discount_rate': '15.69%',\n",
      " 'o_price': '25500',\n",
      " 's_price': '21500',\n",
      " 'title': '[케이스위스] 깔끔하고 편안한 남여 캐주얼 코트화 8종 4116SP104/ 케이스위스'}\n",
      "2019-02-17 20:00:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://item.gmarket.co.kr/Item?goodscode=746916620>\n",
      "{'discount_rate': '70.0%',\n",
      " 'o_price': '23000',\n",
      " 's_price': '6900',\n",
      " 'title': '[릴리푸리] 릴리푸리/빌리진/봄신상/무료배송/원피스/티셔츠/세트'}\n",
      "2019-02-17 20:00:02 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2019-02-17 20:00:02 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 6884,\n",
      " 'downloader/request_count': 14,\n",
      " 'downloader/request_method_count/GET': 14,\n",
      " 'downloader/response_bytes': 367703,\n",
      " 'downloader/response_count': 14,\n",
      " 'downloader/response_status_count/200': 13,\n",
      " 'downloader/response_status_count/302': 1,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2019, 2, 17, 11, 0, 2, 803655),\n",
      " 'item_scraped_count': 10,\n",
      " 'log_count/DEBUG': 24,\n",
      " 'log_count/INFO': 9,\n",
      " 'memusage/max': 51523584,\n",
      " 'memusage/startup': 51523584,\n",
      " 'request_depth_max': 1,\n",
      " 'response_received_count': 13,\n",
      " 'robotstxt/request_count': 2,\n",
      " 'robotstxt/response_count': 2,\n",
      " 'robotstxt/response_status_count/200': 2,\n",
      " 'scheduler/dequeued': 11,\n",
      " 'scheduler/dequeued/memory': 11,\n",
      " 'scheduler/enqueued': 11,\n",
      " 'scheduler/enqueued/memory': 11,\n",
      " 'start_time': datetime.datetime(2019, 2, 17, 11, 0, 0, 677208)}\n",
      "2019-02-17 20:00:02 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "!source run.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>o_price</th>\n",
       "      <th>s_price</th>\n",
       "      <th>discount_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[아디다스] (신세계경기점) MENS RUNNING  플루이드/솔릭스 (CG3820...</td>\n",
       "      <td>39000</td>\n",
       "      <td>27970</td>\n",
       "      <td>28.28%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>김하진 자연육수 다시팩 100팩(멸치/해물/얼큰)</td>\n",
       "      <td>39900</td>\n",
       "      <td>36910</td>\n",
       "      <td>7.49%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NEW 리뉴얼 그로미미 PPSU 빨대컵/빨대젖병 + 교체용빨대2개입</td>\n",
       "      <td>23850</td>\n",
       "      <td>23850</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[디아도라] (신세계강남점)디아도라 컨템포러리 스니커즈 런닝화 14종 택1 DS17...</td>\n",
       "      <td>33000</td>\n",
       "      <td>23350</td>\n",
       "      <td>29.24%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[GFresh] 보성 흑토마토 2kg(대~3번과 혼합)</td>\n",
       "      <td>23800</td>\n",
       "      <td>11900</td>\n",
       "      <td>50.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[비달사순] 비달사순 40mm 아이롱/매직기/봉고데기 VSCD746K</td>\n",
       "      <td>31360</td>\n",
       "      <td>29800</td>\n",
       "      <td>4.97%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>메이킹유 여성 데님/빅사이즈/청바지/루즈핏/셔츠</td>\n",
       "      <td>19700</td>\n",
       "      <td>7900</td>\n",
       "      <td>59.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[이지오] 모다아울렛 S/S 이월 정장세트 5만원 外</td>\n",
       "      <td>20000</td>\n",
       "      <td>20000</td>\n",
       "      <td>0.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[케이스위스] 깔끔하고 편안한 남여 캐주얼 코트화 8종 4116SP104/ 케이스위스</td>\n",
       "      <td>25500</td>\n",
       "      <td>21500</td>\n",
       "      <td>15.69%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[릴리푸리] 릴리푸리/빌리진/봄신상/무료배송/원피스/티셔츠/세트</td>\n",
       "      <td>23000</td>\n",
       "      <td>6900</td>\n",
       "      <td>70.0%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  o_price  s_price  \\\n",
       "0  [아디다스] (신세계경기점) MENS RUNNING  플루이드/솔릭스 (CG3820...    39000    27970   \n",
       "1                        김하진 자연육수 다시팩 100팩(멸치/해물/얼큰)    39900    36910   \n",
       "2              NEW 리뉴얼 그로미미 PPSU 빨대컵/빨대젖병 + 교체용빨대2개입    23850    23850   \n",
       "3  [디아도라] (신세계강남점)디아도라 컨템포러리 스니커즈 런닝화 14종 택1 DS17...    33000    23350   \n",
       "4                     [GFresh] 보성 흑토마토 2kg(대~3번과 혼합)    23800    11900   \n",
       "5             [비달사순] 비달사순 40mm 아이롱/매직기/봉고데기 VSCD746K    31360    29800   \n",
       "6                         메이킹유 여성 데님/빅사이즈/청바지/루즈핏/셔츠    19700     7900   \n",
       "7                      [이지오] 모다아울렛 S/S 이월 정장세트 5만원 外    20000    20000   \n",
       "8    [케이스위스] 깔끔하고 편안한 남여 캐주얼 코트화 8종 4116SP104/ 케이스위스    25500    21500   \n",
       "9                [릴리푸리] 릴리푸리/빌리진/봄신상/무료배송/원피스/티셔츠/세트    23000     6900   \n",
       "\n",
       "  discount_rate  \n",
       "0        28.28%  \n",
       "1         7.49%  \n",
       "2          0.0%  \n",
       "3        29.24%  \n",
       "4         50.0%  \n",
       "5         4.97%  \n",
       "6         59.9%  \n",
       "7          0.0%  \n",
       "8        15.69%  \n",
       "9         70.0%  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('crawler/GmarketBestsellers.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
